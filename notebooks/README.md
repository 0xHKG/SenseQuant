# SenseQuant Notebooks

This directory contains Jupyter notebooks for analyzing trading system performance and telemetry data.

## Available Notebooks

### accuracy_report.ipynb (US-016)

Comprehensive prediction accuracy analysis notebook for **single backtests** that demonstrates:

- **Loading telemetry data**: Import prediction traces from CSV files generated during backtests
- **Computing metrics**: Calculate precision, recall, F1 scores, confusion matrix, and financial metrics
- **Visualization**: Generate publication-ready charts including:
  - Confusion matrix heatmaps
  - Return distribution histograms
  - Precision-recall comparisons
  - Cumulative return curves
- **Export reports**: Save metrics to JSON for archival and comparison

#### Prerequisites

```bash
# Install required packages
pip install jupyter pandas numpy matplotlib seaborn scikit-learn
```

#### Usage

1. **Run a backtest with telemetry enabled**:
   ```python
   from src.services.backtester import Backtester
   from src.domain.types import BacktestConfig

   config = BacktestConfig(
       symbols=["RELIANCE"],
       start_date="2024-01-01",
       end_date="2024-03-31",
       strategy="swing",
       initial_capital=1000000.0,
       data_source="breeze",
       random_seed=42,
   )

   backtester = Backtester(
       config=config,
       enable_telemetry=True,  # Enable telemetry capture
   )

   result = backtester.run()
   ```

2. **Note the batch_id** from the telemetry file names (e.g., `predictions_20241012_143000_0000.csv`)

3. **Open the notebook**:
   ```bash
   jupyter notebook notebooks/accuracy_report.ipynb
   ```

4. **Update configuration** in the first code cell:
   ```python
   batch_id = "20241012_143000"  # Your batch ID
   ```

5. **Run all cells** to generate the complete analysis

#### Output

The notebook generates:
- Confusion matrix plot (PNG)
- Return distribution plot (PNG)
- Precision-recall comparison chart (PNG)
- Cumulative returns chart (PNG)
- Metrics report (JSON)

All outputs are saved to `../data/reports/` by default.

## Directory Structure

```
notebooks/
├── README.md                 # This file
└── accuracy_report.ipynb     # Accuracy analysis notebook

data/
├── analytics/                # Telemetry data (prediction traces)
│   └── predictions_*.csv     # Generated by backtests with telemetry enabled
└── reports/                  # Analysis outputs
    ├── confusion_matrix_*.png
    ├── return_distribution_*.png
    ├── precision_recall_*.png
    ├── cumulative_returns_*.png
    └── accuracy_report_*.json
```

## Tips

- **Use glob patterns** to analyze multiple batch files: `predictions_20241012_*`
- **Compare batches** by running the notebook multiple times with different batch IDs
- **Archive reports** by backing up the `data/reports/` directory periodically
- **Customize plots** by modifying matplotlib/seaborn settings in the notebook
- **Add custom analysis** by creating new cells in the notebook

## Troubleshooting

**"No trace files found"**
- Verify the `batch_id` is correct
- Check that telemetry was enabled during the backtest
- Ensure the `data/analytics/` directory contains trace files

**"No traces to display"**
- The backtest may not have generated any trades
- Check the backtest configuration and data
- Verify the date range includes valid trading days

**Import errors**
- Ensure you're running the notebook from the repository root or adjust the `sys.path` in the notebook
- Install missing dependencies: `pip install -r requirements.txt`

**Plotting errors**
- Ensure matplotlib and seaborn are installed
- Check that you're running in an environment that supports GUI displays (not headless)

### optimization_report.ipynb (US-019 Phase 4)

**NEW!** Parameter optimization analysis notebook for analyzing **batch optimization runs** that provides:

- **Artifact loading**: Load baseline_metrics.json, configs.json, ranked_results.csv from optimization runs
- **Before/After comparison**: Visualize baseline vs optimized configuration metrics
- **Parameter sensitivity**: Analyze which parameters impact performance most (correlation analysis)
- **Top configurations**: Compare top 5 ranked configurations with composite scores
- **Deployment recommendations**: 3-phase rollout plan with rollback strategy
- **Export capabilities**: Generate analysis summary JSON and publication-ready charts

#### Prerequisites

```bash
# Same as accuracy_report.ipynb
pip install jupyter pandas numpy matplotlib seaborn
```

#### Usage

1. **Run parameter optimization**:
   ```bash
   python scripts/optimize.py \
     --config config/optimization/intraday_grid.json \
     --symbols RELIANCE TCS \
     --start-date 2024-01-01 \
     --end-date 2024-12-31 \
     --objective composite \
     --run-baseline \
     --export-report
   ```

2. **Note the optimization run directory** (e.g., `data/optimization/run_20241012_143022`)

3. **Open the optimization notebook**:
   ```bash
   jupyter notebook notebooks/optimization_report.ipynb
   ```

4. **Update configuration** in the first code cell:
   ```python
   optimization_run_dir = "../data/optimization/run_20241012_143022"
   ```

5. **Run all cells** to generate the analysis

#### Output

The notebook generates:
- Before/after comparison chart (PNG)
- Parameter sensitivity analysis (PNG)
- Top 5 configurations chart (PNG)
- Optimization analysis summary (JSON)

All outputs are saved to `../data/reports/` by default.

#### Converting to HTML/PDF

Use nbconvert to export the notebook:

```bash
# Export to HTML
jupyter nbconvert --to html notebooks/optimization_report.ipynb \
  --output-dir=data/reports

# Export to PDF (requires pandoc and texlive)
jupyter nbconvert --to pdf notebooks/optimization_report.ipynb \
  --output-dir=data/reports
```

Or use the provided helper script:

```bash
# Export optimization notebook to HTML/Markdown
python scripts/export_notebook.py optimization_report
```

## Future Enhancements

Potential additions to this notebook collection:

- **Confusion matrix delta visualization**: Compare confusion matrices between baseline and optimized configs (requires per-config telemetry)
- **Feature importance**: Analyze which features drive prediction accuracy
- **Strategy comparison**: Side-by-side comparison of intraday vs swing strategies
- **Real-time monitoring**: Live dashboard for production system monitoring
- **Regime detection**: Analyze performance across different market conditions
- **Walk-forward optimization**: Time-series split optimization with out-of-sample validation

## Contributing

When adding new notebooks:
1. Follow the same structure (markdown explanations + code cells)
2. Make them self-contained and beginner-friendly
3. Include clear configuration parameters at the top
4. Add error handling for missing data
5. Update this README with usage instructions
